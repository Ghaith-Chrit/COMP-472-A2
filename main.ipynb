{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP - 472\n",
    "Assignment Two\n",
    "\n",
    "AI GURUS: James Partsafas, Ghaith Chrit, Samuel Collette\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import nltk \n",
    "import random\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'word2vec-google-news-300'\n",
    "model = api.load(model_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'A2-DataSet/synonym.csv'\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "analysis_output_file = os.path.join('output', f'analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Report result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_details_file(details_output_file_name, df, model):\n",
    "    correct_labels = 0\n",
    "    answered_questions = 0\n",
    "    with open(details_output_file_name, mode='w', newline='') as details_file:\n",
    "      details_writer = csv.writer(details_file)\n",
    "      details_writer.writerow(['question-word', 'correct-answer', 'guess-word', 'label'])\n",
    "\n",
    "      for _, row in df.iterrows():\n",
    "        question_word, correct_answer, guess_words = row['question'], row['answer'], row[2:].to_list()\n",
    "        guess_words_in_vocab = [word for word in guess_words if word in model.index_to_key]\n",
    "\n",
    "        if question_word in model.index_to_key and len(guess_words_in_vocab) > 0:\n",
    "          most_similar_word = model.most_similar_to_given(question_word, guess_words_in_vocab)\n",
    "          label = 'correct' if most_similar_word == correct_answer else 'wrong'\n",
    "          correct_labels += 1 if label == 'correct' else 0\n",
    "          answered_questions += 1\n",
    "        else:\n",
    "          label = 'guess'\n",
    "          most_similar_word = random.choice(guess_words)\n",
    "\n",
    "        details_writer.writerow([question_word, correct_answer, most_similar_word, label])\n",
    "    \n",
    "    return (correct_labels, answered_questions)\n",
    "\n",
    "def write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, write_mode):\n",
    "    accuracy = correct_labels / answered_questions if answered_questions > 0 else 0\n",
    "\n",
    "    with open(analysis_output_file, mode=write_mode, newline='') as analysis_file:\n",
    "      analysis_writer = csv.writer(analysis_file)\n",
    "      if (write_mode == 'w'):  \n",
    "          analysis_writer.writerow(['Model Name', 'Vocab Length', 'Number of Correct Labels', 'Number of Answered Questions', 'Accuracy of Answered Questions'])\n",
    "      analysis_writer.writerow([model_name, len(model.index_to_key), correct_labels, answered_questions, accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "#### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Run two models (Glove-Twitter and Glove-Wiki-Gigaword) with two embedding size (50 and 100) each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['glove-twitter-50', 'glove-wiki-gigaword-50', 'glove-twitter-100', 'glove-wiki-gigaword-100']\n",
    "\n",
    "for model in models:\n",
    "  global model_name\n",
    "\n",
    "  model_name = model\n",
    "  model = api.load(model_name)\n",
    "\n",
    "  details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "  correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "  write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')\n",
    "  \n",
    "  model = None\n",
    "  gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Graph Result For Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy_bar_chart(models, outputFile):\n",
    "    analysis_file = 'output/analysis.csv'\n",
    "    df_analysis = pd.read_csv(analysis_file)\n",
    "    analysis_rows = df_analysis.loc[df_analysis['Model Name'].isin(models)]\n",
    "    \n",
    "    students_file = 'A2-DataSet/COMP-472-per-question.csv'\n",
    "    df_students = pd.read_csv(students_file, encoding='UTF-16 LE')\n",
    "    students_average_row = df_students.loc[0]\n",
    "    \n",
    "    accuracy_data = {'Baseline': 25, 'Students': students_average_row['Accuracy']}\n",
    "    for _, row in analysis_rows.iterrows():\n",
    "        accuracy_data[row['Model Name']] = row['Accuracy of Answered Questions'] * 100\n",
    "\n",
    "    keys = list(accuracy_data.keys())\n",
    "    values = list(accuracy_data.values())\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(keys, values)\n",
    "    ax.tick_params(axis='x', labelrotation=90, labelsize=6)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy of different models')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outputFile, dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_bar_chart(['word2vec-google-news-300', 'glove-twitter-50', 'glove-wiki-gigaword-50', 'glove-twitter-100', 'glove-wiki-gigaword-100'], 'output/task2_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "#### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Preprocesing all the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(urls):\n",
    "    all_tokens = []\n",
    "    \n",
    "    for url in urls:\n",
    "        response = request.urlopen(url)\n",
    "        raw = response.read().decode('utf8')\n",
    "        tokens_sen = nltk.sent_tokenize(raw)\n",
    "        \n",
    "        tokenized_sentences = []\n",
    "        for sen in tokens_sen:\n",
    "            words = nltk.word_tokenize(sen)\n",
    "            tokenized_sentences.append(words)\n",
    "        \n",
    "        all_tokens.extend(tokenized_sentences)\n",
    "    \n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Train a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(tokens, window_size, embedding_size):\n",
    "    name = f'custom-corpus-{embedding_size}-{window_size}'\n",
    "    model = Word2Vec(sentences = tokens, window = window_size, vector_size=embedding_size)\n",
    "    model.wv.save(f'output/custom-models/{name}.w2v')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Train models with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.gutenberg.org/cache/epub/2600/pg2600.txt\",   # war-and-peace\n",
    "    \"https://www.gutenberg.org/cache/epub/28054/pg28054.txt\", # brothers-karamazov\n",
    "    \"https://www.gutenberg.org/cache/epub/2554/pg2554.txt\",   # crime-and-punishment\n",
    "    \"https://www.gutenberg.org/cache/epub/7178/pg7178.txt\",   # Swann's-Way\n",
    "    \"https://www.gutenberg.org/cache/epub/1399/pg1399.txt\",   # Anna-Karenina\n",
    "]\n",
    "\n",
    "names = []\n",
    "tokens = preprocess(urls)\n",
    "\n",
    "window_sizes = [3, 5]\n",
    "embedding_sizes = [50, 100]\n",
    "\n",
    "for window_size, embedding_size in product(window_sizes, embedding_sizes):\n",
    "    global model_name\n",
    "\n",
    "    model_name = train_model(tokens, window_size, embedding_size)\n",
    "    model = KeyedVectors.load(f'output/custom-models/{model_name}.w2v')\n",
    "\n",
    "    names.append(model_name)\n",
    "    details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "    correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "    write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')\n",
    "\n",
    "    model = None\n",
    "    gc.collect()\n",
    "\n",
    "create_accuracy_bar_chart(names, 'output/task3_accuracy.png')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
