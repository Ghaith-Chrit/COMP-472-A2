{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP - 472\n",
    "Assignment Two\n",
    "\n",
    "AI GURUS: James Partsafas, Ghaith Chrit, Samuel Collette\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import random\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from urllib import request\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"starting model load\")\n",
    "model_name = 'word2vec-google-news-300'\n",
    "model = KeyedVectors.load_word2vec_format(api.load(model_name, return_path=True), binary=True) \n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'A2-DataSet/synonym.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Run the model on test data and report result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not ('model_name' in locals())):\n",
    "    model_name = \"\"\n",
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "analysis_output_file = os.path.join('output', f'analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_details_file(details_output_file_name, df, model):\n",
    "    correct_labels = 0\n",
    "    answered_questions = 0\n",
    "    with open(details_output_file_name, mode='w', newline='') as details_file:\n",
    "      details_writer = csv.writer(details_file)\n",
    "      details_writer.writerow(['question-word', 'correct-answer', 'guess-word', 'label'])\n",
    "\n",
    "      for _, row in df.iterrows():\n",
    "        question_word, correct_answer, guess_words = row['question'], row['answer'], row[2:].to_list()\n",
    "        guess_words_in_vocab = [word for word in guess_words if word in model.index_to_key]\n",
    "\n",
    "        if question_word in model.index_to_key and len(guess_words_in_vocab) > 0:\n",
    "          most_similar_word = model.most_similar_to_given(question_word, guess_words_in_vocab)\n",
    "          label = 'correct' if most_similar_word == correct_answer else 'wrong'\n",
    "          correct_labels += 1 if label == 'correct' else 0\n",
    "          answered_questions += 1\n",
    "        else:\n",
    "          label = 'guess'\n",
    "          most_similar_word = random.choice(guess_words)\n",
    "\n",
    "        details_writer.writerow([question_word, correct_answer, most_similar_word, label])\n",
    "    \n",
    "    return (correct_labels, answered_questions)\n",
    "\n",
    "def write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, write_mode):\n",
    "    accuracy = correct_labels / answered_questions if answered_questions > 0 else 0\n",
    "\n",
    "    with open(analysis_output_file, mode=write_mode, newline='') as analysis_file:\n",
    "      analysis_writer = csv.writer(analysis_file)\n",
    "      if (write_mode == 'w'):  \n",
    "          analysis_writer.writerow(['Model Name', 'Vocab Length', 'Number of Correct Labels', 'Number of Answered Questions', 'Accuracy of Answered Questions'])\n",
    "      analysis_writer.writerow([model_name, len(model.index_to_key), correct_labels, answered_questions, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 79\n"
     ]
    }
   ],
   "source": [
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23550"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rid model to clear memory\n",
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# First of 2 models with same embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-twitter-50'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 78\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Second of 2 models with same embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-wiki-gigaword-50'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 80\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# First of 2 models with different embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-twitter-25'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 78\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Second of 2 models with different embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-wiki-gigaword-100'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 80\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy_bar_chart(models,outputFile):\n",
    "    analysis_file = 'output/analysis.csv'\n",
    "    df_analysis = pd.read_csv(analysis_file)\n",
    "    analysis_rows = df_analysis.loc[df_analysis['Model Name'].isin(models)]\n",
    "    \n",
    "    students_file = 'A2-DataSet/COMP-472-per-question.csv'\n",
    "    df_students = pd.read_csv(students_file, encoding='UTF-16 LE')\n",
    "    students_average_row = df_students.loc[0]\n",
    "    \n",
    "    accuracy_data = {'Baseline': 50, 'Students': students_average_row['Accuracy']}\n",
    "    for _, row in analysis_rows.iterrows():\n",
    "        accuracy_data[row['Model Name']] = row['Accuracy of Answered Questions'] * 100\n",
    "        \n",
    "    keys = list(accuracy_data.keys())\n",
    "    values = list(accuracy_data.values())\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(keys, values)\n",
    "    ax.tick_params(axis='x', labelrotation = 30)\n",
    "    plt.gcf().subplots_adjust(bottom=0.4)\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy of different models')\n",
    "    \n",
    "    plt.savefig(outputFile)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_bar_chart(['glove-twitter-50', 'glove-wiki-gigaword-50', 'glove-twitter-25', 'glove-wiki-gigaword-100'],'output/task2_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "#### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(url) -> list:\n",
    "    response = request.urlopen(url)\n",
    "    raw=response.read().decode('utf8')\n",
    "    tokens_sen=nltk.sent_tokenize(raw)\n",
    "    i=0\n",
    "    for sen in tokens_sen:\n",
    "        words= nltk.word_tokenize(sen)\n",
    "        tokens_sen[i]=words\n",
    "        i+=1\n",
    "    return tokens_sen\n",
    "\n",
    "def model_creation_and_output(modName,tokens,windowSizes:list, vectorSizes:list):\n",
    "    i = 0\n",
    "    global model,model_name\n",
    "    while i < len(vectorSizes):\n",
    "        j=0\n",
    "        while j < len(windowSizes):\n",
    "            print(\"starting model load\")\n",
    "            model_name = f'word2vec-{modName}-{vectorSizes[i]}-{windowSizes[j]}'\n",
    "            model = Word2Vec(sentences = tokens, window = windowSizes[j], vector_size=vectorSizes[i])\n",
    "            word_vectors = model.wv\n",
    "            word_vectors.save('vectors.kv')\n",
    "            model = KeyedVectors.load('vectors.kv')\n",
    "            print(\"model loaded\")\n",
    "\n",
    "            details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "            correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "            print(correct_labels, answered_questions)\n",
    "            \n",
    "            write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')\n",
    "            j+=1\n",
    "        i+=1\n",
    "\n",
    "def multi_bar_chart(vectorSizes,windowSizes,names):\n",
    "    \n",
    "    model_name_list=[]\n",
    "    \n",
    "    i=0\n",
    "    while i < len(vectorSizes):\n",
    "        j=0\n",
    "        while j < len(windowSizes):\n",
    "            for name in names:\n",
    "                model_name_list.append(f'word2vec-{name}-{vectorSizes[i]}-{windowSizes[j]}') \n",
    "            create_accuracy_bar_chart(model_name_list, f'output/task3_accuracy-{vectorSizes[i]}-{windowSizes[j]}.png')\n",
    "            model_name_list=[]\n",
    "            j+=1\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables, and preprocesing the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://www.gutenberg.org/cache/epub/2600/pg2600.txt\" #war-and-peace\n",
    "url2 = \"https://www.gutenberg.org/cache/epub/28054/pg28054.txt\" #brothers-karamazov\n",
    "url3 = \"https://www.gutenberg.org/cache/epub/2554/pg2554.txt\" #crime-and-punishment\n",
    "url4 = \"https://www.gutenberg.org/cache/epub/7178/pg7178.txt\" #Swann's-Way\n",
    "url5 = \"https://www.gutenberg.org/cache/epub/1399/pg1399.txt\" #Anna-Karenina\n",
    "  \n",
    "tokens_url1 = preprocess(url1) \n",
    "tokens_url2 = preprocess(url2) \n",
    "tokens_url3 = preprocess(url3) \n",
    "tokens_url4 = preprocess(url4) \n",
    "tokens_url5 = preprocess(url5) \n",
    "\n",
    "window_size = [5,3]\n",
    "\n",
    "vector_size = [100,50]\n",
    "\n",
    "names = [\"war-and-peace\",\"brothers-karamazov\",\"crime-and-punishment\",\"Swann's-Way\",\"Anna-Karenina\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating models, writing output to files, and creating bar charts to compare easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "model loaded\n",
      "8 29\n",
      "starting model load\n",
      "model loaded\n",
      "7 29\n",
      "starting model load\n",
      "model loaded\n",
      "7 29\n",
      "starting model load\n",
      "model loaded\n",
      "5 29\n",
      "starting model load\n",
      "model loaded\n",
      "10 23\n",
      "starting model load\n",
      "model loaded\n",
      "9 23\n",
      "starting model load\n",
      "model loaded\n",
      "8 23\n",
      "starting model load\n",
      "model loaded\n",
      "8 23\n",
      "starting model load\n",
      "model loaded\n",
      "7 16\n",
      "starting model load\n",
      "model loaded\n",
      "8 16\n",
      "starting model load\n",
      "model loaded\n",
      "9 16\n",
      "starting model load\n",
      "model loaded\n",
      "6 16\n",
      "starting model load\n",
      "model loaded\n",
      "7 19\n",
      "starting model load\n",
      "model loaded\n",
      "7 19\n",
      "starting model load\n",
      "model loaded\n",
      "9 19\n",
      "starting model load\n",
      "model loaded\n",
      "7 19\n",
      "starting model load\n",
      "model loaded\n",
      "7 21\n",
      "starting model load\n",
      "model loaded\n",
      "4 21\n",
      "starting model load\n",
      "model loaded\n",
      "7 21\n",
      "starting model load\n",
      "model loaded\n",
      "5 21\n"
     ]
    }
   ],
   "source": [
    "model_creation_and_output(\"war-and-peace\",tokens_url1,window_size,vector_size)\n",
    "model_creation_and_output(\"brothers-karamazov\",tokens_url2,window_size,vector_size)\n",
    "model_creation_and_output(\"crime-and-punishment\",tokens_url3,window_size,vector_size)\n",
    "model_creation_and_output(\"Swann's-Way\",tokens_url4,window_size,vector_size)\n",
    "model_creation_and_output(\"Anna-Karenina\",tokens_url5,window_size,vector_size)\n",
    "\n",
    "multi_bar_chart(vector_size,window_size,names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
