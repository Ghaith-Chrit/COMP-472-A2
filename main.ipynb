{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP - 472\n",
    "Assignment Two\n",
    "\n",
    "AI GURUS: James Partsafas, Ghaith Chrit, Samuel Collette\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"starting model load\")\n",
    "model_name = 'word2vec-google-news-300'\n",
    "model = KeyedVectors.load_word2vec_format(api.load(model_name, return_path=True), binary=True) \n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'A2-DataSet/synonym.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Run the model on test data and report result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not ('model_name' in locals())):\n",
    "    model_name = \"\"\n",
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "analysis_output_file = os.path.join('output', f'analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_details_file(details_output_file_name, df, model):\n",
    "    correct_labels = 0\n",
    "    answered_questions = 0\n",
    "    with open(details_output_file_name, mode='w', newline='') as details_file:\n",
    "      details_writer = csv.writer(details_file)\n",
    "      details_writer.writerow(['question-word', 'correct-answer', 'guess-word', 'label'])\n",
    "\n",
    "      for _, row in df.iterrows():\n",
    "        question_word, correct_answer, guess_words = row['question'], row['answer'], row[2:].to_list()\n",
    "        guess_words_in_vocab = [word for word in guess_words if word in model.index_to_key]\n",
    "\n",
    "        if question_word in model.index_to_key and len(guess_words_in_vocab) > 0:\n",
    "          most_similar_word = model.most_similar_to_given(question_word, guess_words_in_vocab)\n",
    "          label = 'correct' if most_similar_word == correct_answer else 'wrong'\n",
    "          correct_labels += 1 if label == 'correct' else 0\n",
    "          answered_questions += 1\n",
    "        else:\n",
    "          label = 'guess'\n",
    "          most_similar_word = random.choice(guess_words)\n",
    "\n",
    "        details_writer.writerow([question_word, correct_answer, most_similar_word, label])\n",
    "    \n",
    "    return (correct_labels, answered_questions)\n",
    "\n",
    "def write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, write_mode):\n",
    "    accuracy = correct_labels / answered_questions if answered_questions > 0 else 0\n",
    "\n",
    "    with open(analysis_output_file, mode=write_mode, newline='') as analysis_file:\n",
    "      analysis_writer = csv.writer(analysis_file)\n",
    "      if (write_mode == 'w'):  \n",
    "          analysis_writer.writerow(['Model Name', 'Vocab Length', 'Number of Correct Labels', 'Number of Answered Questions', 'Accuracy of Answered Questions'])\n",
    "      analysis_writer.writerow([model_name, len(model.index_to_key), correct_labels, answered_questions, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 79\n"
     ]
    }
   ],
   "source": [
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rid model to clear memory\n",
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# First of 2 models with same embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-twitter-50'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 78\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Second of 2 models with same embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-wiki-gigaword-50'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 80\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# First of 2 models with different embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-twitter-25'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 78\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model load\n",
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Second of 2 models with different embedding size\n",
    "print(\"starting model load\")\n",
    "model_name = 'glove-wiki-gigaword-100'\n",
    "model = api.load(model_name)\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 80\n"
     ]
    }
   ],
   "source": [
    "details_output_file = os.path.join('output', f'{model_name}-details.csv')\n",
    "correct_labels, answered_questions = create_details_file(details_output_file, df, model)\n",
    "print(correct_labels, answered_questions)\n",
    "\n",
    "write_to_analysis_file(analysis_output_file, correct_labels, answered_questions, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy_bar_chart(models):\n",
    "    analysis_file = 'output/analysis.csv'\n",
    "    df_analysis = pd.read_csv(analysis_file)\n",
    "    analysis_rows = df_analysis.loc[df_analysis['Model Name'].isin(models)]\n",
    "    \n",
    "    students_file = 'A2-DataSet/COMP-472-per-question.csv'\n",
    "    df_students = pd.read_csv(students_file, encoding='UTF-16 LE')\n",
    "    students_average_row = df_students.loc[0]\n",
    "    \n",
    "    accuracy_data = {'Baseline': 25, 'Students': students_average_row['Accuracy']}\n",
    "    for _, row in analysis_rows.iterrows():\n",
    "        accuracy_data[row['Model Name']] = row['Accuracy of Answered Questions'] * 100\n",
    "\n",
    "    keys = list(accuracy_data.keys())\n",
    "    values = list(accuracy_data.values())\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(keys, values)\n",
    "    ax.tick_params(axis='x', labelrotation=90, labelsize=6)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy of different models')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/task2_accuracy.png', dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_bar_chart(['word2vec-google-news-300', 'glove-twitter-50', 'glove-wiki-gigaword-50', 'glove-twitter-25', 'glove-wiki-gigaword-100'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add code for task 3 here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
